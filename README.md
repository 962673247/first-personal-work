# first-personal-work
爬取数据部分
    首先爬虫的话很熟悉哈，上学期刚刚学基本知识都记得，打开腾讯视频网页一看，大概就知道是 ajax 异步加载的问题，要么用 selenium ，要么就去抓包，点了几下更多评论，我去...一下才      
刷出来十条，我傻了，果断放弃 selenium ，F12 开始分析，点了几个之后基本上就发现了规律，我们这边可以拿2个 url 去对比一下
https://video.coral.qq.com/varticle/5963120294/comment/v2callback=_varticle5963120294commentv2&orinum=10&oriorder=o&pageflag=1&cursor=6716709711492873145&scorecursor=0&orirepnum=2&reporder=o&reppageflag=1&source=132&_=1614071261726
https://video.coral.qq.com/varticle/5963120294/comment/v2callback=_varticle5963120294commentv2&orinum=10&oriorder=o&pageflag=1&cursor=6716753294460916527&scorecursor=0&orirepnum=2&reporder=o&reppageflag=1&source=132&_=1614071261727
这里看这起来 url 很长，其实一对比就两个地方不一样，这个 cursor 和最后的一串数字，我们先来看这个 cursor 哈，第一条这个数据的 cursor 都是0(多次刷新网页的时候有时候可以看到第一条，大部分时候都看不到第一条这个数据)，根据我们以往对这类异步加载的经验，往往下一条的 url 请求参数都隐藏在上一条的数据之中，这里复制下一条的 cursor 去上一条的 url 数据里面 ctrl+f 一搜索，果然就出现了，
![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223171415779-1777650967.png)
这里我们注意到后面还有个 hasnext ，很容易猜想到是不是判断有没有下面的评论的依据，这也是我们抓包循环结束的条件， cursor 分析完之后我们再来看最后一串数据，几条之后不难分析出每次都加1的缘故（事实上我发现规律的后一天晚上再次打开网页的时候发现有时候不是加1，是加2或者加3，找了半天没找到这个加项，可能是网站改了反爬策略，好在第二天再次看网页的时候发现又恢复了+1的规律，这也告诉了我们爬虫作业要早点做，像我这样拖拉的很容易前功尽弃），找到规律之后大家应该都在想，那第一个是什么呢？，第一个是怎么构造出来的呢，刚开始想可能是隐藏在网页源码里面，ctrl+f 之后并不是，看着这串数字，我想到了上学期爬虫的时候也遇到过类似的数据，时间戳，在进入网页的时候根据时间生成的时间戳，13位的应该是毫秒级别的，生成一下当前时间戳在对比网页的基本一样，这样我们对ajax这个异步加载的规律就完全找到，接下来只要一集一集爬取就可以了。
   在对比后面几集的url发现在数据包里面还有一串数字是亘古不变的，
![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223172402863-393095727.png)
这前面一串是什么数字的，也不管那么多，直接复制到网页源码那边搜索一下，果然
![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223172439694-649384482.png)
这个数字隐藏在网页源码之中，也就是说每一集的网页都附带着这种数字，用来构造请求数据包的参数，那就是说我们需要获取所有网页的这串数字，问题再次转移到所有集的网页的构造，因为一共有20集，20集的url你都要构造出来，然后去获得里面的这串数字，进而爬取评论，当然你也可以把这20集的网页的url全部复制，然后一个个爬...但是作为学习计算机的人员肯定要倔强的分析一下，把网页url分析了一下，发现
![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223172856726-1714176480.png)

  其中只有 u0034zxdhdi 这串字母是特别的，老规矩丢到网页源码一搜索，果然还是老套路，下一集的 url 构造参数隐藏在上一集的源码里面，但是在我多搜索几次之后发现
  原来这里一集就有着20集网页全部的参数，正好一次性全部提取了，
  ![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223173622205-1468470996.png)
  至此，网页爬取的分析过程全部结束，然后就是代码的编写。
  爬取每集的url构造参数
  ![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223173749692-1630422884.png)
  根据上面获得的url爬取抓包参数
  ![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223173834047-14902703.png)
  循环构造数据包url并爬取评论
  ![](https://img2020.cnblogs.com/blog/1538768/202102/1538768-20210223173911001-1406994311.png)
  爬虫完成
